# SME Pulse â€“ ML-First Feature Store Architecture

> **Má»¥c tiÃªu**: XÃ¢y dá»±ng **Feature Store trong Silver** (training truth), **Gold** cho BI/Analytics serve, vá»›i **CI/CD ML pipeline** vÃ  **data quality guardrails**. TÃ­ch há»£p **Kaggle Invoices Dataset** cho AR/Payment Prediction.

---

## âš ï¸ Váº¤N Äá»€ Cáº¬U Gáº¶P & FIX

### **Sai láº§m ban Ä‘áº§u** âŒ
```
Gold Layer = Direct training data + Feature engineering
```
**Váº¥n Ä‘á»:**
- Gold = business aggregations (daily_revenue, KPIs) â†’ high-level, lossy
- ML cáº§n raw/semi-processed data (rows khÃ´ng aggregate)
- Thay Ä‘á»•i business logic á»Ÿ Gold â†’ phÃ¡ mÃ´ hÃ¬nh cÅ©
- BI vÃ  ML team cÃ¹ng edit Gold â†’ conflict

### **Best Practice** âœ…
```
Silver = Feature Store (training truth, detailed)
Gold = Aggregates + Score serve (BI dashboards + model predictions)
ML Pipeline = Train tá»« Silver, score Ä‘Æ°a vÃ o Gold
```

**Lá»£i Ã­ch:**
- **Separation of concerns**: BI team khÃ´ng áº£nh hÆ°á»Ÿng Data Science
- **Reproducibility**: Feature khÃ´ng bá»‹ thay Ä‘á»•i khi BI update KPI
- **Governance**: Feature engineering cÃ³ version, audit trail
- **Latency**: BI query Gold (aggregate, fast), ML train tá»« Silver (detailed, fresh)

---

## ğŸ“ KIáº¾N TRÃšC Má»šI

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   LAKEHOUSE â€“ ML-FIRST                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  BRONZE (Immutable Raw)                                      â”‚
â”‚  â”œâ”€ sales_snapshot_raw                                       â”‚
â”‚  â”œâ”€ payments_raw                                             â”‚
â”‚  â”œâ”€ shipments_raw                                            â”‚
â”‚  â”œâ”€ bank_txn_raw                                             â”‚
â”‚  â”œâ”€ kaggle_invoices_train.csv    â† â­ NEW                    â”‚
â”‚  â””â”€ kaggle_invoices_test.csv     â† â­ NEW                    â”‚
â”‚                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  SILVER â€“ FEATURE STORE (Training Truth)                     â”‚
â”‚  â”œâ”€ ğŸ“Š Base Staging Tables (cleaned, typed, Vietnamized)    â”‚
â”‚  â”‚  â”œâ”€ stg_orders_vn                                         â”‚
â”‚  â”‚  â”œâ”€ stg_payments_vn                                       â”‚
â”‚  â”‚  â”œâ”€ stg_shipments_vn                                      â”‚
â”‚  â”‚  â”œâ”€ stg_bank_txn_vn                                       â”‚
â”‚  â”‚  â””â”€ stg_ar_invoices_vn        â† â­ NEW (from Kaggle)      â”‚
â”‚  â”‚                                                           â”‚
â”‚  â”œâ”€ ğŸ”„ Feature Engineering Tables (for ML)                  â”‚
â”‚  â”‚  â”œâ”€ ftr_customer_behavior     â† RFM, churn risk          â”‚
â”‚  â”‚  â”œâ”€ ftr_invoice_risk          â† DSO, overdue rate        â”‚
â”‚  â”‚  â”œâ”€ ftr_payment_pattern       â† avg days late, methods   â”‚
â”‚  â”‚  â”œâ”€ ftr_seasonality           â† month, quarter effects   â”‚
â”‚  â”‚  â””â”€ ftr_macroeconomic         â† world bank rates          â”‚
â”‚  â”‚                                                           â”‚
â”‚  â””â”€ ğŸ¯ ML Training Datasets (fact + features, no leakage)   â”‚
â”‚     â”œâ”€ ml_training_payment_pred  â† Labels + features        â”‚
â”‚     â”œâ”€ ml_training_ar_scoring    â† Invoice + payment label  â”‚
â”‚     â””â”€ ml_training_cashflow_fcst â† Time series features     â”‚
â”‚                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  GOLD â€“ ANALYTICS & SERVE LAYER                              â”‚
â”‚  â”œâ”€ ğŸ“Š Conformed Dimensions                                  â”‚
â”‚  â”‚  â”œâ”€ dim_date, dim_customer, dim_product, ...              â”‚
â”‚  â”‚  â””â”€ dim_ar_customer           â† â­ NEW (AR behavior)     â”‚
â”‚  â”‚                                                           â”‚
â”‚  â”œâ”€ ğŸ“ˆ Fact Tables (for BI)                                  â”‚
â”‚  â”‚  â”œâ”€ fact_orders               â† Daily snapshot           â”‚
â”‚  â”‚  â”œâ”€ fact_payments                                        â”‚
â”‚  â”‚  â”œâ”€ fact_shipments                                       â”‚
â”‚  â”‚  â”œâ”€ fact_bank_txn                                        â”‚
â”‚  â”‚  â””â”€ fact_ar_invoices          â† â­ NEW (DSO, overdue)    â”‚
â”‚  â”‚                                                           â”‚
â”‚  â”œâ”€ ğŸ”— Link Tables (reconciliation)                         â”‚
â”‚  â”‚  â”œâ”€ link_order_payment                                   â”‚
â”‚  â”‚  â”œâ”€ link_payment_bank                                    â”‚
â”‚  â”‚  â””â”€ link_order_shipment                                  â”‚
â”‚  â”‚                                                           â”‚
â”‚  â”œâ”€ ğŸ“Š KPI Marts (for BI dashboards)                        â”‚
â”‚  â”‚  â”œâ”€ kpi_daily_revenue         â† Safe aggregates         â”‚
â”‚  â”‚  â”œâ”€ kpi_payment_success_rate                            â”‚
â”‚  â”‚  â”œâ”€ kpi_ar_dso_analysis       â† â­ NEW                   â”‚
â”‚  â”‚  â””â”€ kpi_reconciliation_daily                            â”‚
â”‚  â”‚                                                          â”‚
â”‚  â””â”€ ğŸ¤– ML Score Serve (model predictions)                   â”‚
â”‚     â”œâ”€ score_payment_pred        â† Pred payment date       â”‚
â”‚     â”œâ”€ score_ar_priority         â† Collection priority      â”‚
â”‚     â”œâ”€ score_churn_risk          â† Customer churn risk      â”‚
â”‚     â””â”€ score_cashflow_fcst       â† Predicted cash-in        â”‚
â”‚                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  ğŸš€ ML PIPELINE (External Orchestration)                     â”‚
â”‚  â”œâ”€ Data Validation              â† Great Expectations       â”‚
â”‚  â”œâ”€ Feature Preparation          â† SQL â†’ Python DF          â”‚
â”‚  â”œâ”€ Model Training               â† Prophet, SKLearn, XGBoostâ”‚
â”‚  â”œâ”€ Model Evaluation             â† Cross-validation         â”‚
â”‚  â”œâ”€ Model Versioning             â† MLflow, DVC              â”‚
â”‚  â””â”€ Score Writing Back           â† Score â†’ Gold tables      â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¯ LAYER RESPONSIBILITIES

### **Silver = Feature Store (Training Truth)**

**TÃ­nh cháº¥t:**
- **Versioned**: Má»—i thay Ä‘á»•i feature â†’ táº¡o version má»›i
- **Detailed**: Row-level data, khÃ´ng aggregate
- **Curated**: ÄÃ£ clean, type-cast, handle missing
- **Lineage**: Track feature tá»« Bronze source
- **Searchable**: Feature metadata catalog

**Ai sá»­ dá»¥ng:**
- Data Scientists (train models)
- ML Engineers (feature development)
- Data Analysts (exploratory analysis)

**SLA:**
- Data freshness: Real-time â†’ Hourly
- Availability: 99%
- Retention: 2-3 years (for retraining)

### **Gold = Analytics & Serve (BI + Model Output)**

**TÃ­nh cháº¥t:**
- **Aggregated**: Pre-calculated KPIs, business metrics
- **Denormalized**: Star schema, optimized for queries
- **Served**: Model scores, predictions
- **Governed**: Row-level security, masking
- **Fast**: Optimized for BI tools (Metabase, Power BI)

**Ai sá»­ dá»¥ng:**
- Business Analysts (dashboards)
- Executives (KPI reports)
- Applications (model scores API)

**SLA:**
- Query latency: < 5 seconds
- Availability: 99.9%
- Retention: 1-2 years (compliance)

---

## ğŸ“‹ SILVER LAYER DESIGN

### **1. Base Staging Tables** (Cleaned & Vietnamized)

Already exist, vÃ­ dá»¥:
- `stg_orders_vn` â† Orders with revenue, cost
- `stg_payments_vn` â† Payments with status, amount_vnd
- `stg_ar_invoices_vn` â† NEW: AR invoices from Kaggle

### **2. Feature Engineering Tables** (Calculated, NOT Aggregated)

These are **at row-level or slowly-changing dimensions**, designed for ML feature engineering.

#### **silver/features/ftr_customer_behavior.sql**
```sql
-- Customer-level features (slowly changing)
-- 1 row per customer = stable reference
{{ config(
    materialized='incremental',
    unique_key='customer_code',
    on_schema_change='append_new_columns',
    tags=['feature_store', 'customer_features']
) }}

with orders as (
    select 
        customer_code,
        count(*) as total_orders_ltm,
        sum(qty) as total_qty_ltm,
        sum(revenue) as total_revenue_ltm,
        avg(revenue) as avg_order_value,
        max(order_date) as last_order_date,
        min(order_date) as first_order_date,
        datediff('day', min(order_date), max(order_date)) as customer_age_days
    from {{ ref('stg_orders_vn') }}
    where order_date >= dateadd('month', -12, current_date)
    group by 1
),
payments as (
    select 
        customer_code,
        count(*) as total_payments_ltm,
        sum(amount_vnd) as total_paid_ltm,
        sum(case when status_std = 'paid' then 1 else 0 end) as paid_count,
        sum(case when status_std = 'pending' then 1 else 0 end) as pending_count
    from {{ ref('stg_payments_vn') }}
    where payment_date >= dateadd('month', -12, current_date)
    group by 1
),
combined as (
    select
        o.customer_code,
        o.total_orders_ltm,
        o.total_qty_ltm,
        o.total_revenue_ltm,
        o.avg_order_value,
        o.last_order_date,
        o.customer_age_days,
        
        -- RFM Features
        datediff('day', o.last_order_date, current_date) as recency_days,
        o.total_orders_ltm as frequency,
        o.total_revenue_ltm as monetary,
        
        -- Payment Features
        coalesce(p.total_payments_ltm, 0) as total_payments_ltm,
        coalesce(p.paid_count, 0) as paid_count,
        coalesce(p.pending_count, 0) as pending_count,
        case 
            when o.total_orders_ltm > 0 
            then round(1.0 * coalesce(p.paid_count, 0) / o.total_orders_ltm, 3)
            else 0 
        end as payment_completion_rate,
        
        -- Segment
        case
            when o.total_revenue_ltm > 1000000000 and datediff('day', o.last_order_date, current_date) <= 30 then 'VIP'
            when o.total_orders_ltm >= 10 and datediff('day', o.last_order_date, current_date) <= 30 then 'Active'
            when datediff('day', o.last_order_date, current_date) > 90 then 'Inactive'
            else 'At Risk'
        end as customer_segment,
        
        current_timestamp as ftr_updated_at
    from orders o
    left join payments p on o.customer_code = p.customer_code
)
select * from combined;
```

#### **silver/features/ftr_invoice_risk.sql**
```sql
-- Invoice-level risk features (row per invoice)
{{ config(
    materialized='incremental',
    unique_key='invoice_id',
    on_schema_change='append_new_columns',
    tags=['feature_store', 'ar_features']
) }}

with invoices as (
    select
        invoice_id,
        customer_number,
        business_code,
        invoice_date,
        baseline_create_date,
        due_date,
        payment_date,
        invoice_amount,
        isOpen,
        isLate,
        
        -- Days Overdue calculation
        case
            when isOpen = true then datediff('day', due_date, current_date)
            when payment_date is not null then datediff('day', due_date, payment_date)
            else 0
        end as days_overdue,
        
        -- Days to Pay
        case
            when payment_date is not null then datediff('day', invoice_date, payment_date)
            else null
        end as days_to_pay,
        
        -- Invoice aging
        datediff('day', due_date, current_date) as aging_days
    from {{ ref('stg_ar_invoices_vn') }}
),
risk_features as (
    select
        invoice_id,
        customer_number,
        business_code,
        invoice_amount,
        invoice_date,
        due_date,
        payment_date,
        days_overdue,
        days_to_pay,
        aging_days,
        
        -- Risk flags
        case when days_overdue > 30 then 1 else 0 end as is_overdue_30,
        case when days_overdue > 60 then 1 else 0 end as is_overdue_60,
        case when isOpen = true and aging_days > 90 then 1 else 0 end as is_high_risk,
        
        -- Invoice size bracket
        case
            when invoice_amount < 10000000 then 'small'
            when invoice_amount < 100000000 then 'medium'
            else 'large'
        end as invoice_size_bracket,
        
        current_timestamp as ftr_updated_at
    from invoices
)
select * from risk_features;
```

#### **silver/features/ftr_payment_pattern.sql**
```sql
-- Customer payment pattern features (slowly changing)
{{ config(
    materialized='incremental',
    unique_key='customer_code',
    on_schema_change='append_new_columns',
    tags=['feature_store', 'payment_features']
) }}

with payment_history as (
    select
        customer_code,
        method_code,
        payment_date,
        amount_vnd,
        status_std,
        datediff('day', payment_date, lag(payment_date) over (partition by customer_code order by payment_date)) as days_between_payments
    from {{ ref('stg_payments_vn') }}
    where payment_date >= dateadd('month', -12, current_date)
),
aggregated as (
    select
        customer_code,
        
        -- Payment method preference
        mode(method_code) as preferred_payment_method,
        
        -- Payment timing
        avg(days_between_payments) as avg_days_between_payments,
        stddev(days_between_payments) as stddev_days_between_payments,
        
        -- Payment reliability
        round(sum(case when status_std = 'paid' then 1 else 0 end) * 1.0 / count(*), 3) as payment_success_rate,
        
        current_timestamp as ftr_updated_at
    from payment_history
    group by customer_code
)
select * from aggregated;
```

### **3. ML Training Datasets** (Fact + Features, No Data Leakage)

#### **silver/ml_training/ml_training_payment_pred.sql**
```sql
-- Training dataset for payment date prediction model
-- Features: invoice + customer behavior
-- Label: days_to_pay
-- Constraint: Use historical invoices only (no future data leak)

{{ config(
    materialized='table',
    tags=['feature_store', 'ml_training', 'payment_prediction']
) }}

with invoices as (
    select
        invoice_id,
        customer_number,
        invoice_amount,
        invoice_date,
        due_date,
        payment_date,
        baseline_create_date,
        business_code,
        
        -- Label: Days to pay (only for paid invoices)
        datediff('day', invoice_date, payment_date) as days_to_pay
    from {{ ref('ftr_invoice_risk') }}
    where payment_date is not null  -- Only completed invoices
      and invoice_date >= dateadd('year', -2, current_date)  -- 2 years history
      and days_to_pay >= 0  -- No negative days
      and days_to_pay <= 180  -- Remove outliers
),
customer_feats as (
    select 
        customer_code,
        payment_completion_rate,
        customer_age_days,
        recency_days,
        frequency,
        monetary
    from {{ ref('ftr_customer_behavior') }}
),
payment_patterns as (
    select
        customer_code,
        preferred_payment_method,
        avg_days_between_payments,
        payment_success_rate
    from {{ ref('ftr_payment_pattern') }}
),
combined as (
    select
        i.invoice_id,
        i.customer_number,
        i.invoice_amount,
        i.invoice_date,
        i.due_date,
        i.business_code,
        i.days_to_pay as target_days_to_pay,
        
        -- Customer features
        cf.payment_completion_rate,
        cf.customer_age_days,
        cf.recency_days,
        cf.frequency,
        cf.monetary,
        
        -- Payment pattern features
        coalesce(pp.preferred_payment_method, 'unknown') as preferred_payment_method,
        coalesce(pp.avg_days_between_payments, 0) as avg_days_between_payments,
        coalesce(pp.payment_success_rate, 0) as payment_success_rate,
        
        -- Time features
        month(i.invoice_date) as invoice_month,
        quarter(i.invoice_date) as invoice_quarter,
        dayofweek(i.invoice_date) as invoice_dayofweek,
        
        current_timestamp as training_prepared_at
    from invoices i
    left join customer_feats cf on i.customer_number = cf.customer_code
    left join payment_patterns pp on i.customer_number = pp.customer_code
)
select * from combined;
```

---

## ğŸ“Š GOLD LAYER DESIGN

### **New Dimensions for AR**

#### **gold/dims/dim_ar_customer.sql** (SCD Type 2)
```sql
-- AR Customer dimension with history
{{ config(
    materialized='incremental',
    unique_key=['customer_code', 'effective_from'],
    tags=['dimensions', 'ar_dimensions']
) }}

with customer_feats as (
    select
        customer_code,
        payment_completion_rate,
        customer_segment,
        ftr_updated_at
    from {{ ref('ftr_customer_behavior') }}
),
scd_logic as (
    select
        customer_code,
        payment_completion_rate,
        customer_segment,
        ftr_updated_at as effective_from,
        dateadd('day', -1, lead(ftr_updated_at) over (partition by customer_code order by ftr_updated_at)) as effective_to,
        case when lead(ftr_updated_at) over (partition by customer_code order by ftr_updated_at) is null 
             then true else false end as is_current
    from customer_feats
)
select 
    {{ dbt_utils.surrogate_key(['customer_code', 'effective_from']) }} as ar_customer_key,
    customer_code,
    payment_completion_rate,
    customer_segment,
    effective_from,
    effective_to,
    is_current
from scd_logic;
```

### **Fact Tables for AR**

#### **gold/facts/fact_ar_invoices.sql** (DSO Analysis)
```sql
-- AR invoice facts for DSO, overdue analysis
{{ config(
    materialized='incremental',
    unique_key='invoice_key',
    tags=['facts', 'ar_facts']
) }}

with invoices as (
    select
        ir.invoice_id,
        cast(to_char(ir.invoice_date, 'YYYYMMDD') as bigint) as date_key_invoice,
        cast(to_char(ir.due_date, 'YYYYMMDD') as bigint) as date_key_due,
        ir.customer_number as customer_key,
        ir.business_code,
        ir.invoice_amount,
        ir.days_overdue,
        ir.is_overdue_30,
        ir.is_overdue_60,
        ir.is_high_risk,
        ir.invoice_size_bracket,
        case when ir.payment_date is not null then 'paid' else 'open' end as status
    from {{ ref('ftr_invoice_risk') }} ir
)
select
    {{ dbt_utils.surrogate_key(['invoice_id', 'date_key_invoice']) }} as invoice_key,
    invoice_id,
    date_key_invoice,
    date_key_due,
    customer_key,
    business_code,
    invoice_amount,
    days_overdue,
    is_overdue_30,
    is_overdue_60,
    is_high_risk,
    invoice_size_bracket,
    status
from invoices;
```

### **KPI Marts for BI**

#### **gold/kpi/kpi_ar_dso_analysis.sql**
```sql
-- Days Sales Outstanding (DSO) and AR analytics
{{ config(
    materialized='incremental',
    unique_key='date_key',
    tags=['kpi', 'ar_kpi']
) }}

with daily_metrics as (
    select
        date_key_invoice as date_key,
        count(distinct invoice_id) as total_invoices,
        sum(invoice_amount) as total_invoice_amount,
        sum(case when status = 'paid' then invoice_amount else 0 end) as paid_amount,
        sum(case when status = 'open' then invoice_amount else 0 end) as open_amount,
        
        -- Overdue metrics
        sum(is_overdue_30) as invoices_overdue_30,
        sum(is_overdue_60) as invoices_overdue_60,
        sum(is_high_risk) as high_risk_invoices,
        
        -- DSO calculation (simplified)
        round(avg(days_overdue), 2) as avg_days_overdue,
        
        current_timestamp as kpi_updated_at
    from {{ ref('fact_ar_invoices') }}
    group by date_key_invoice
)
select * from daily_metrics;
```

### **ML Score Serve Tables**

#### **gold/ml_scores/score_payment_pred.sql**
```sql
-- Model predictions: predicted payment date
-- Updated by ML pipeline after model inference
{{ config(
    materialized='incremental',
    unique_key='invoice_id',
    tags=['ml_scores', 'payment_prediction']
) }}

select
    invoice_id,
    customer_number,
    predicted_days_to_pay,
    predicted_payment_date,
    model_version,
    prediction_confidence,
    prediction_timestamp,
    current_timestamp as score_inserted_at
from {{ source('ml_pipeline', 'payment_pred_scores') }}
where prediction_timestamp >= dateadd('day', -7, current_date);
```

---

## ğŸ”„ ML PIPELINE ORCHESTRATION

### **Architecture: Airflow â†’ Python â†’ MLflow â†’ dbt**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Airflow DAG: ml_training_daily    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                     â”‚
â”‚ 1. data_quality_check               â”‚
â”‚    â””â”€ Great Expectations on Silver  â”‚
â”‚                                     â”‚
â”‚ 2. feature_preparation              â”‚
â”‚    â””â”€ SQL query Silver features     â”‚
â”‚    â””â”€ Load to Pandas                â”‚
â”‚                                     â”‚
â”‚ 3. model_training                   â”‚
â”‚    â””â”€ Train Prophet/XGBoost/LGBM    â”‚
â”‚    â””â”€ MLflow tracking               â”‚
â”‚                                     â”‚
â”‚ 4. model_evaluation                 â”‚
â”‚    â””â”€ Cross-validation metrics      â”‚
â”‚    â””â”€ Artifact logging              â”‚
â”‚                                     â”‚
â”‚ 5. batch_inference                  â”‚
â”‚    â””â”€ Inference on recent data      â”‚
â”‚    â””â”€ Write scores to temp table    â”‚
â”‚                                     â”‚
â”‚ 6. dbt_load_scores                  â”‚
â”‚    â””â”€ dbt run --select gold.ml_scores
â”‚    â””â”€ Tests on score data           â”‚
â”‚                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **dbt Tags for Orchestration**

ThÃªm `dbt_project.yml`:
```yaml
models:
  sme_pulse:
    silver:
      +tags: ['silver', 'feature_store']
      features:
        +tags: ['silver', 'feature_store', 'ml_features']
      ml_training:
        +tags: ['silver', 'feature_store', 'ml_training_dataset']
    
    gold:
      +tags: ['gold', 'analytics']
      ml_scores:
        +tags: ['gold', 'ml_scores', 'production']
        +meta:
          owner: ml_platform
          sla: critical
```

---

## ğŸ›¡ï¸ DATA QUALITY GUARDRAILS

### **1. Great Expectations for Silver Features**

File: `dbt/tests/ge/feature_quality.py`
```python
import great_expectations as gx
from great_expectations.core.batch import RuntimeBatchRequest

def validate_features_before_training():
    context = gx.get_context()
    
    # Check stg_ar_invoices_vn
    batch_request = RuntimeBatchRequest(
        datasource_name="trino",
        data_connector_name="default",
        data_asset_name="silver.stg_ar_invoices_vn"
    )
    
    suite = context.suites.add(gx.ExpectationSuite(name="invoice_quality"))
    validator = context.get_validator(batch_request=batch_request, expectation_suite=suite)
    
    # Expectations
    validator.expect_column_to_exist("invoice_id")
    validator.expect_column_values_to_not_be_null("invoice_amount")
    validator.expect_column_values_to_be_between("invoice_amount", min_value=0)
    validator.expect_column_values_to_not_have_trailing_whitespace("customer_number")
    
    # Stat expectations (distribution shift detection)
    validator.expect_column_mean_to_be_between("invoice_amount", min_value=15000000, max_value=25000000)
    validator.expect_column_kl_divergence_from_list_to_be_less_than(
        "business_code", 
        partition_column="business_code",
        threshold=0.2  # KL divergence limit
    )
    
    checkpoint = validator.save_expectation_suite(discard_failed_expectations=False)
    results = context.run_checkpoint(checkpoint_name=suite.name)
    
    return results.success
```

### **2. dbt Tests for Features**

File: `dbt/tests/custom_tests.sql`
```sql
-- tests/feature_store_quality.sql
-- Ensure features don't have sudden changes

select
    ftr_customer_behavior.customer_code,
    ftr_customer_behavior.payment_completion_rate,
    lag(ftr_customer_behavior.payment_completion_rate, 1) over (
        partition by ftr_customer_behavior.customer_code 
        order by ftr_customer_behavior.ftr_updated_at
    ) as prev_rate
from {{ ref('ftr_customer_behavior') }}
where abs(
    ftr_customer_behavior.payment_completion_rate - 
    lag(ftr_customer_behavior.payment_completion_rate, 1) over (
        partition by ftr_customer_behavior.customer_code 
        order by ftr_customer_behavior.ftr_updated_at
    )
) > 0.3  -- Flag > 30% change in completion rate
having prev_rate is not null
```

### **3. Airflow Pipeline Guardrails**

File: `airflow/dags/ml_training_pipeline.py`
```python
from airflow import DAG
from airflow.operators.python import PythonOperator
from airflow.operators.bash import BashOperator
from datetime import datetime, timedelta
import pandas as pd
from trino.dbapi import connect

default_args = {
    'owner': 'ml_platform',
    'retries': 2,
    'retry_delay': timedelta(minutes=5),
    'email_on_failure': True,
    'email': ['ml_team@sme-pulse.vn']
}

dag = DAG(
    'ml_training_daily',
    default_args=default_args,
    schedule_interval='0 2 * * *',  # 2 AM every day
    tags=['ml', 'production']
)

def data_quality_check():
    """
    Pre-training guardrails:
    - Check null %
    - Check distribution shift (KL divergence)
    - Check data freshness
    """
    conn = connect(host='trino', port=8080, database='iceberg', schema='silver')
    
    # 1. Null check
    query_null = """
    SELECT 
        COUNT(*) as total_rows,
        SUM(CASE WHEN invoice_id IS NULL THEN 1 ELSE 0 END) as null_invoice_id,
        SUM(CASE WHEN invoice_amount IS NULL THEN 1 ELSE 0 END) as null_amount
    FROM stg_ar_invoices_vn
    WHERE invoice_date >= DATE(CURRENT_DATE - INTERVAL 7 DAY)
    """
    df_null = pd.read_sql(query_null, conn)
    null_rate = df_null['null_invoice_id'].values[0] / df_null['total_rows'].values[0]
    
    if null_rate > 0.05:  # > 5% nulls = fail
        raise ValueError(f"Too many nulls in invoice_id: {null_rate*100:.2f}%")
    
    # 2. Freshness check
    query_fresh = "SELECT MAX(invoice_date) as max_date FROM stg_ar_invoices_vn"
    df_fresh = pd.read_sql(query_fresh, conn)
    max_date = pd.to_datetime(df_fresh['max_date'].values[0])
    
    if (datetime.now() - max_date).days > 2:  # Data > 2 days old = warning
        raise ValueError(f"Data is stale: {max_date}")
    
    print(f"âœ… Data quality check passed: {null_rate*100:.2f}% nulls, freshness OK")

def feature_preparation():
    """Load features from Silver, prepare for training"""
    # Query features from Silver
    # Save to training CSV for model pipeline
    pass

def model_training_with_tracking():
    """Train model with MLflow tracking"""
    import mlflow
    from prophet import Prophet
    import numpy as np
    
    mlflow.set_experiment("payment_prediction")
    
    with mlflow.start_run():
        # Prepare data
        df_train = pd.read_csv('/tmp/training_data.csv')
        
        # Log parameters
        mlflow.log_param("model_type", "Prophet")
        mlflow.log_param("training_rows", len(df_train))
        
        # Train
        model = Prophet(yearly_seasonality=True, weekly_seasonality=True)
        model.fit(df_train[['ds', 'y']])  # ds = date, y = target
        
        # Evaluate
        metrics = cross_validate(model, df_train, horizon=7, period=30, parallel="processes")
        mape = np.mean(metrics['mape'])
        
        mlflow.log_metric("MAPE", mape)
        mlflow.log_artifact(model, "prophet_model")
        
        print(f"âœ… Model trained with MAPE: {mape:.4f}")

def batch_inference():
    """Generate predictions for all active invoices"""
    # Load trained model from MLflow
    # Inference on Silver features
    # Write scores to temp table
    pass

task_check = PythonOperator(
    task_id='data_quality_check',
    python_callable=data_quality_check,
    dag=dag
)

task_prep = PythonOperator(
    task_id='feature_preparation',
    python_callable=feature_preparation,
    dag=dag
)

task_train = PythonOperator(
    task_id='model_training',
    python_callable=model_training_with_tracking,
    dag=dag
)

task_infer = PythonOperator(
    task_id='batch_inference',
    python_callable=batch_inference,
    dag=dag
)

task_dbt = BashOperator(
    task_id='dbt_load_scores',
    bash_command='cd /opt/dbt && dbt run --select gold.ml_scores --threads 4',
    dag=dag
)

task_check >> task_prep >> task_train >> task_infer >> task_dbt
```

---

## ğŸ“¥ KAGGLE INVOICES INTEGRATION

### **Step 1: Download & Ingest**

#### **airflow/dags/ingest_kaggle_invoices.py**
```python
from airflow import DAG
from airflow.operators.python import PythonOperator
from datetime import datetime, timedelta
import pandas as pd
import subprocess
import os
from minio import Minio

dag = DAG(
    'ingest_kaggle_invoices',
    schedule_interval='@monthly',  # Once per month
    tags=['bronze', 'kaggle', 'ar']
)

def download_kaggle_dataset():
    """
    Download Kaggle dataset
    Prerequisites:
    - Kaggle API key installed: ~/.kaggle/kaggle.json
    - In Dockerfile: pip install kaggle
    """
    dataset = "pradumn203/payment-date-prediction-for-invoices-dataset"
    output_path = "/tmp/kaggle_invoices"
    
    os.makedirs(output_path, exist_ok=True)
    
    # Download
    subprocess.run([
        "kaggle", "datasets", "download", 
        "-d", dataset, 
        "-p", output_path,
        "--unzip"
    ], check=True)
    
    print(f"âœ… Downloaded to {output_path}")
    return output_path

def upload_to_minio(output_path):
    """Upload to MinIO bronze layer"""
    client = Minio(
        "minio:9000",
        access_key="minioadmin",
        secret_key="minioadmin123",
        secure=False
    )
    
    ingest_date = datetime.now().strftime("%Y%m%d")
    bucket = "sme-lake"
    
    for csv_file in ['train.csv', 'test.csv']:
        file_path = f"{output_path}/{csv_file}"
        object_name = f"bronze/raw/kaggle_invoices/{ingest_date}/{csv_file}"
        
        client.fput_object(bucket, object_name, file_path)
        print(f"âœ… Uploaded {object_name}")

task_download = PythonOperator(
    task_id='download_kaggle',
    python_callable=download_kaggle_dataset,
    dag=dag
)

task_upload = PythonOperator(
    task_id='upload_to_minio',
    python_callable=upload_to_minio,
    dag=dag
)

task_download >> task_upload
```

### **Step 2: Bronze â†’ Silver Transformation**

#### **models/silver/stg_ar_invoices_vn.sql**
```sql
-- AR invoices from Kaggle dataset
-- Mapping Kaggle columns â†’ SME Pulse standard

{{ config(
    materialized='incremental',
    unique_key='invoice_id',
    on_schema_change='sync_all_columns',
    tags=['silver', 'ar_invoices', 'kaggle']
) }}

with src as (
    select * from {{ source('bronze', 'kaggle_invoices_raw') }}
),
normalized as (
    select
        -- Unique identifiers
        {{ dbt_utils.surrogate_key(['invoice_id']) }} as invoice_id_nat,
        invoice_id,
        customer_number,
        business_code,
        
        -- Dates (Kaggle â†’ Standard format)
        try_to_date(invoice_date, 'DD-MMM-YYYY') as invoice_date,
        try_to_date(baseline_create_date, 'DD-MMM-YYYY') as baseline_create_date,
        try_to_date(due_in_date, 'DD-MMM-YYYY') as due_date,
        try_to_date(clear_date, 'DD-MMM-YYYY') as payment_date,
        
        -- Amount fields
        try_cast(total_open_amount as decimal(18,2)) as invoice_amount,
        
        -- Status flags
        case 
            when isOpen = 1 then true
            when isOpen = 0 then false
            else null 
        end as isOpen,
        case
            when isLate = 1 then true
            when isLate = 0 then false
            else null
        end as isLate,
        
        -- Additional features from Kaggle
        supply_days,
        credit_limit,
        business_year,
        
        current_timestamp as ingested_at
    from src
    where invoice_date >= dateadd('year', -3, current_date)  -- 3 years history
)
select * from normalized
{% if is_incremental() %}
  where ingested_at > (select max(ingested_at) from {{ this }})
{% endif %}
```

### **Step 3: Bronze Source Declaration**

#### **models/bronze.yml** (add)
```yaml
sources:
  - name: bronze
    schema: bronze
    tables:
      # ... existing tables ...
      - name: kaggle_invoices_raw
        description: "Kaggle Invoices Dataset - Payment Date Prediction"
        columns:
          - name: invoice_id
            description: Unique invoice identifier
          - name: customer_number
            tests:
              - not_null
          - name: invoice_date
          - name: due_in_date
          - name: clear_date
          - name: total_open_amount
            tests:
              - not_null
```

---

## ğŸ“‹ CI/CD ML WORKFLOW

### **Git Strategy: Feature Branches for Models**

```bash
# Data Scientist creates feature branch
git checkout -b feature/ml-payment-prediction

# 1. Modify Silver features
# - Edit silver/features/ftr_invoice_risk.sql
# - dbt run --select silver.features

# 2. Create training dataset
# - Edit silver/ml_training/ml_training_payment_pred.sql
# - dbt run --select silver.ml_training

# 3. Train locally
# python scripts/train_payment_model.py

# 4. Push & open PR
git push origin feature/ml-payment-prediction

# On PR:
# - CI runs: dbt test --select silver.*
# - CI runs: dbt docs generate
# - Requires code review from ML Lead
# - Merge to main

# On main merge:
# - CD trigger: dbt build
# - CD trigger: Airflow dag update
# - CD trigger: Model retrain (if features changed)
```

---

## ğŸ¯ USE CASES MAPPING

### **UC05: AR Management**
```sql
-- Query Gold (not Silver!)
select
  f.invoice_id,
  d.customer_code,
  f.invoice_amount,
  f.due_date,
  f.days_overdue,
  f.is_high_risk,
  s.predicted_payment_date,
  s.prediction_confidence
from gold.fact_ar_invoices f
join gold.dim_ar_customer d on f.customer_key = d.ar_customer_key
left join gold.score_payment_pred s on f.invoice_id = s.invoice_id
where f.is_high_risk = true
order by f.days_overdue desc
```

### **UC09: Forecast Cashflow**
```sql
-- Combine payment prediction + Silver features
select
  s.predicted_payment_date,
  sum(f.invoice_amount) as predicted_cash_in
from silver.ml_training_payment_pred f
join gold.score_payment_pred s on f.invoice_id = s.invoice_id
group by s.predicted_payment_date
order by s.predicted_payment_date
```

### **UC10: Anomaly Detection**
```sql
-- Compare actual vs predicted (via ML scores)
select
  s.predicted_payment_date,
  f.payment_date,
  datediff('day', s.predicted_payment_date, f.payment_date) as prediction_error_days,
  case 
    when abs(datediff('day', s.predicted_payment_date, f.payment_date)) > 14 then 'anomaly'
    else 'normal'
  end as flag
from gold.fact_ar_invoices f
join gold.score_payment_pred s on f.invoice_id = s.invoice_id
where f.payment_date is not null
  and abs(datediff('day', s.predicted_payment_date, f.payment_date)) > 7
```

---

## âœ… DEFINITION OF DONE

### **Silver Layer (Feature Store)**
- [ ] All base staging tables cleaned & Vietnamized
- [ ] Feature engineering tables created with business logic
- [ ] Training datasets have correct grain (no data leakage)
- [ ] Great Expectations quality rules written
- [ ] dbt tests for distribution shift detection
- [ ] Feature metadata documented (owner, SLA, update frequency)
- [ ] `dbt test` pass on all Silver models

### **Gold Layer (Analytics & Serve)**
- [ ] Conformed dimensions (SCD Type 0, 1, 2 as needed)
- [ ] Fact tables with surrogate keys to dims
- [ ] Link tables for reconciliation
- [ ] KPI marts pre-calculated for BI
- [ ] ML score serve tables with version tracking
- [ ] Row-level security configured
- [ ] `dbt test` pass on all Gold models

### **ML Pipeline (Orchestration)**
- [ ] Airflow DAG for data quality â†’ training â†’ inference
- [ ] MLflow experiment tracking for model versions
- [ ] Guardrails: Great Expectations + dbt tests
- [ ] CI/CD for feature changes (code review required)
- [ ] Model artifact versioning (MLflow or DVC)
- [ ] Batch inference writes scores to Gold daily
- [ ] Monitoring: prediction accuracy on holdout set

### **Kaggle Invoices Integration**
- [ ] Download script with Kaggle API
- [ ] Bronze: Raw CSVs in MinIO
- [ ] Silver: `stg_ar_invoices_vn` with all fields normalized
- [ ] Gold: `fact_ar_invoices` + `dim_ar_customer`
- [ ] KPI: `kpi_ar_dso_analysis` in Metabase
- [ ] ML training dataset includes Kaggle invoices
- [ ] `dbt test` pass with 500k+ rows

### **Documentation**
- [ ] README: Feature Store catalog with lineage
- [ ] dbt docs: `dbt docs generate` published
- [ ] ML handbook: Model training workflow, evaluation metrics
- [ ] Data dictionary: All columns, transformations, freshness
- [ ] Glossary: Terms (DSO, overdue, MAPE, etc.)

---

## ğŸš€ EXECUTION CHECKLIST

```bash
# 1. Setup Kaggle API
pip install kaggle
# ~/.kaggle/kaggle.json (get from kaggle.com/settings/account)

# 2. Add Kaggle dataset to Airflow
# - Create ingest_kaggle_invoices.py DAG
# - Test manually: python scripts/test_kaggle_download.py

# 3. Create Silver feature layers
dbt run --select silver.features
dbt run --select silver.ml_training
dbt test --select silver.*

# 4. Create Gold AR layers
dbt run --select gold.dims.dim_ar_customer
dbt run --select gold.facts.fact_ar_invoices
dbt run --select gold.kpi.kpi_ar_dso_analysis
dbt test --select gold.*

# 5. Setup ML pipeline
# - MLflow server: mlflow server --backend-store-uri sqlite:///mlflow.db --default-artifact-root s3://sme-lake/mlflow
# - Create training scripts (Prophet, XGBoost, etc.)
# - Deploy Airflow DAG: ml_training_daily

# 6. Deploy ML score serving
# - dbt run --select gold.ml_scores
# - Airflow: batch_inference â†’ score writing

# 7. Monitor & validate
dbt build --selector build_warehouse
```

---

## ï¿½ Cáº¤U TRÃšC THÆ¯ Má»¤C Dá»° ÃN

```
sme_pulse/
â”‚
â”œâ”€ README.md
â”œâ”€ dbt_project.yml                    # â­ Config chÃ­nh
â”œâ”€ profiles.yml                       # Trino connection
â”œâ”€ packages.yml                       # dbt-utils, etc.
â”œâ”€ selectors.yml                      # Build workflow
â”‚
â”œâ”€ seeds/                             # ğŸŒ± Reference data
â”‚  â”œâ”€ seed_channel_map.csv
â”‚  â”œâ”€ seed_payment_method_map.csv
â”‚  â”œâ”€ seed_carrier_map.csv
â”‚  â”œâ”€ seed_fx_rates.csv
â”‚  â”œâ”€ seed_provinces.csv
â”‚  â””â”€ seed_vn_holidays.csv
â”‚
â”œâ”€ models/
â”‚  â”‚
â”‚  â”œâ”€ bronze.yml                      # ğŸ”Œ Source declarations
â”‚  â”‚
â”‚  â”œâ”€ silver/                         # ğŸ¥ˆ Feature Store Layer
â”‚  â”‚  â”œâ”€ _silver__models.yml          # Properties & tests
â”‚  â”‚  â”‚
â”‚  â”‚  â”œâ”€ staging/
â”‚  â”‚  â”‚  â”œâ”€ stg_orders_vn.sql         # Orders cleaned
â”‚  â”‚  â”‚  â”œâ”€ stg_payments_vn.sql       # Payments cleaned
â”‚  â”‚  â”‚  â”œâ”€ stg_shipments_vn.sql      # Shipments cleaned
â”‚  â”‚  â”‚  â”œâ”€ stg_bank_txn_vn.sql       # Bank transactions
â”‚  â”‚  â”‚  â””â”€ stg_ar_invoices_vn.sql    # â­ NEW: Kaggle invoices
â”‚  â”‚  â”‚
â”‚  â”‚  â”œâ”€ features/                    # ğŸ”„ ML Feature Engineering
â”‚  â”‚  â”‚  â”œâ”€ ftr_customer_behavior.sql # RFM, segment, payment history
â”‚  â”‚  â”‚  â”œâ”€ ftr_invoice_risk.sql      # DSO, overdue flags
â”‚  â”‚  â”‚  â”œâ”€ ftr_payment_pattern.sql   # Payment method, timing
â”‚  â”‚  â”‚  â”œâ”€ ftr_seasonality.sql       # Temporal features
â”‚  â”‚  â”‚  â””â”€ ftr_macroeconomic.sql     # WB indicators joined
â”‚  â”‚  â”‚
â”‚  â”‚  â””â”€ ml_training/                 # ğŸ¯ Training Datasets (no leakage)
â”‚  â”‚     â”œâ”€ ml_training_payment_pred.sql
â”‚  â”‚     â”œâ”€ ml_training_ar_scoring.sql
â”‚  â”‚     â””â”€ ml_training_cashflow_fcst.sql
â”‚  â”‚
â”‚  â””â”€ gold/                           # ğŸ¥‡ Analytics Ready Layer
â”‚     â”œâ”€ _gold__models.yml            # Properties & tests
â”‚     â”‚
â”‚     â”œâ”€ dims/                        # ğŸ“Š Conformed Dimensions
â”‚     â”‚  â”œâ”€ dim_date.sql              # SCD Type 0 (slowly changing)
â”‚     â”‚  â”œâ”€ dim_customer.sql          # SCD Type 2 (with history)
â”‚     â”‚  â”œâ”€ dim_product.sql           # SCD Type 1 (latest)
â”‚     â”‚  â”œâ”€ dim_channel.sql           # SCD Type 0
â”‚     â”‚  â”œâ”€ dim_payment_method.sql    # SCD Type 0
â”‚     â”‚  â”œâ”€ dim_carrier.sql           # SCD Type 0
â”‚     â”‚  â”œâ”€ dim_geo.sql               # SCD Type 1
â”‚     â”‚  â””â”€ dim_ar_customer.sql       # â­ NEW: SCD Type 2 for AR
â”‚     â”‚
â”‚     â”œâ”€ facts/                       # ğŸ“ˆ Fact Tables (Grain = detail)
â”‚     â”‚  â”œâ”€ fact_orders.sql           # 1 row = 1 order line
â”‚     â”‚  â”œâ”€ fact_payments.sql         # 1 row = 1 payment
â”‚     â”‚  â”œâ”€ fact_shipments.sql        # 1 row = 1 shipment
â”‚     â”‚  â”œâ”€ fact_bank_txn.sql         # 1 row = 1 bank txn
â”‚     â”‚  â””â”€ fact_ar_invoices.sql      # â­ NEW: 1 row = 1 invoice
â”‚     â”‚
â”‚     â”œâ”€ links/                       # ğŸ”— Reconciliation Bridges (M:N)
â”‚     â”‚  â”œâ”€ link_order_payment.sql    # Orders â†” Payments
â”‚     â”‚  â”œâ”€ link_payment_bank.sql     # Payments â†” Bank
â”‚     â”‚  â””â”€ link_order_shipment.sql   # Orders â†” Shipments
â”‚     â”‚
â”‚     â”œâ”€ kpi/                         # ğŸ“Š KPI Marts (for BI dashboards)
â”‚     â”‚  â”œâ”€ kpi_daily_revenue.sql     # Daily revenue + cost
â”‚     â”‚  â”œâ”€ kpi_payment_success_rate.sql
â”‚     â”‚  â”œâ”€ kpi_reconciliation_daily.sql
â”‚     â”‚  â””â”€ kpi_ar_dso_analysis.sql   # â­ NEW: DSO, overdue analysis
â”‚     â”‚
â”‚     â””â”€ ml_scores/                   # ğŸ¤– ML Predictions Served
â”‚        â”œâ”€ score_payment_pred.sql    # Predicted payment date
â”‚        â”œâ”€ score_ar_priority.sql     # Collection priority score
â”‚        â”œâ”€ score_churn_risk.sql      # Customer churn risk
â”‚        â””â”€ score_cashflow_fcst.sql   # Predicted cash-in
â”‚
â”œâ”€ macros/                            # ğŸ”§ Reusable SQL functions
â”‚  â”œâ”€ get_custom_schema.sql
â”‚  â””â”€ dbt_utils_override/             # Override dbt-utils macros
â”‚     â””â”€ trino__get_tables_by_pattern_sql.sql
â”‚
â”œâ”€ tests/                             # ğŸ§ª Custom dbt tests
â”‚  â”œâ”€ feature_store_quality.sql       # Feature stability checks
â”‚  â”œâ”€ fact_grain_tests.sql            # Verify fact table grain
â”‚  â””â”€ link_reconciliation_tests.sql   # Link table validation
â”‚
â”œâ”€ analyses/                          # ğŸ“Š Ad-hoc analysis queries
â”‚  â””â”€ dso_trend_analysis.sql
â”‚
â””â”€ docs/                              # ğŸ“š Documentation
   â”œâ”€ architecture.md
   â”œâ”€ feature_catalog.md
   â””â”€ data_dictionary.md
```

---

## ğŸ”„ DATA FLOW DIAGRAMS

### **Diagram 1: End-to-End Data Flow (Bronze â†’ Silver â†’ Gold)**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  EXTERNAL SOURCES  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ CSV uploads      â”‚
â”‚ â€¢ APIs (World Bank)â”‚
â”‚ â€¢ Kaggle datasets  â”‚
â”‚ â€¢ Bank feeds       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      BRONZE LAYER (Raw, Immutable)     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ sales_snapshot_raw       (orders)    â”‚
â”‚ â€¢ payments_raw             (payments)  â”‚
â”‚ â€¢ shipments_raw            (shipments) â”‚
â”‚ â€¢ bank_txn_raw             (bank)      â”‚
â”‚ â€¢ kaggle_invoices_raw      (invoices) â­
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚ (Airflow: dbt run)
                  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   SILVER LAYER (Feature Store - Training Truth)  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                  â”‚
â”‚  Staging Tables (Cleaned & Typed)                â”‚
â”‚  â”œâ”€ stg_orders_vn                                â”‚
â”‚  â”œâ”€ stg_payments_vn                              â”‚
â”‚  â”œâ”€ stg_shipments_vn                             â”‚
â”‚  â”œâ”€ stg_bank_txn_vn                              â”‚
â”‚  â””â”€ stg_ar_invoices_vn                    â­     â”‚
â”‚                                                  â”‚
â”‚  Feature Engineering (Row-level)                 â”‚
â”‚  â”œâ”€ ftr_customer_behavior (1 row/customer)      â”‚
â”‚  â”œâ”€ ftr_invoice_risk (1 row/invoice)            â”‚
â”‚  â”œâ”€ ftr_payment_pattern (1 row/customer)        â”‚
â”‚  â””â”€ ftr_seasonality (1 row/day)                 â”‚
â”‚                                                 â”‚
â”‚  ML Training Datasets (Fact + Features)         â”‚
â”‚  â”œâ”€ ml_training_payment_pred                    â”‚
â”‚  â”œâ”€ ml_training_ar_scoring                      â”‚
â”‚  â””â”€ ml_training_cashflow_fcst                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ (dbt run --select gold.*)    â”‚
         â†“                              â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Gold: BI/KPI â”‚          â”‚ ML Pipeline (ext.)  â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤          â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚ â€¢ dims       â”‚          â”‚ â€¢ Data QC (GX)      â”‚
    â”‚ â€¢ facts      â”‚          â”‚ â€¢ Feature prep      â”‚
    â”‚ â€¢ kpis       â”‚          â”‚ â€¢ Model training    â”‚
    â”‚ â€¢ links      â”‚          â”‚ â€¢ Inference         â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†‘                             â”‚
         â”‚                            â†“
         â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚                    â”‚ ML Scores (temp)   â”‚
         â”‚                    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
         â”‚                    â”‚ â€¢ predictions      â”‚
         â”‚                    â”‚ â€¢ confidence       â”‚
         â”‚                    â”‚ â€¢ version          â”‚
         â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                             â”‚
         â”‚                    (dbt run --select gold.ml_scores)
         â”‚                             â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â†“
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚   GOLD ML SCORES SERVE   â”‚
         â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
         â”‚ â€¢ score_payment_pred     â”‚
         â”‚ â€¢ score_ar_priority      â”‚
         â”‚ â€¢ score_churn_risk       â”‚
         â”‚ â€¢ score_cashflow_fcst    â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â†“
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  BI TOOLS & DASHBOARDS   â”‚
         â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
         â”‚ â€¢ Metabase               â”‚
         â”‚ â€¢ Looker                 â”‚
         â”‚ â€¢ Power BI               â”‚
         â”‚ â€¢ APIs                   â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **Diagram 2: Feature Store Design Pattern**

```
DATA SCIENTIST WORKFLOW
========================

    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚    Silver: Feature Store (Training)     â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚                                         â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
    â”‚  â”‚ stg_orders_vn                    â”‚   â”‚
    â”‚  â”‚ (raw staging, Vietnamized)       â”‚   â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
    â”‚               â”‚                         â”‚
    â”‚               â†“                         â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
    â”‚  â”‚ ftr_customer_behavior            â”‚   â”‚
    â”‚  â”‚ â€¢ RFM: Recency, Frequency, Money â”‚   â”‚
    â”‚  â”‚ â€¢ Payment rate, customer segment â”‚   â”‚
    â”‚  â”‚ â€¢ Churn signals, LTV             â”‚   â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
    â”‚               â”‚                         â”‚
    â”‚               â†“                         â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
    â”‚  â”‚ ml_training_payment_pred         â”‚   â”‚
    â”‚  â”‚ â€¢ Features: 30+ columns          â”‚   â”‚
    â”‚  â”‚ â€¢ Label: days_to_pay             â”‚   â”‚
    â”‚  â”‚ â€¢ No data leakage                â”‚   â”‚
    â”‚  â”‚ â€¢ Grain: 1 row = 1 invoice      â”‚   â”‚
    â”‚  â”‚ â€¢ 500k+ rows (Kaggle history)    â”‚   â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
    â”‚               â”‚                         â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â”‚ (Export to CSV / Pandas)
                    â†“
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  MLflow Experiment       â”‚
         â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
         â”‚ â€¢ Train: Prophet, XGBoostâ”‚
         â”‚ â€¢ Eval: MAPE, RMSE       â”‚
         â”‚ â€¢ Log: Artifacts, model  â”‚
         â”‚ â€¢ Version: Git hash      â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â†“
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ Model Registry           â”‚
         â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
         â”‚ â€¢ Champion model         â”‚
         â”‚ â€¢ Production stage       â”‚
         â”‚ â€¢ Version: v1.2.3        â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â†“
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ Batch Inference          â”‚
         â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
         â”‚ â€¢ Load model v1.2.3      â”‚
         â”‚ â€¢ Score on Silver feats  â”‚
         â”‚ â€¢ Write predictions      â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Gold: ML Scores Table       â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚ â€¢ score_payment_pred         â”‚
    â”‚ â€¢ 1 row = 1 invoice          â”‚
    â”‚ â€¢ predicted_date, confidence â”‚
    â”‚ â€¢ model_version, timestamp   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  dbt Tests (Gold)            â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚ âœ… Not null scores           â”‚
    â”‚ âœ… Confidence in [0,1]       â”‚
    â”‚ âœ… Recent predictions        â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **Diagram 3: Silver vs Gold Layer Separation**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 FEATURE STORE (SILVER)                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                         â”‚
â”‚  Purpose: Training Machine Learning Models              â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•               â”‚
â”‚                                                         â”‚
â”‚  âœ… Row-level data (no aggregation)                     â”‚
â”‚  âœ… Historical data (2-3 years)                         â”‚
â”‚  âœ… Feature versioning (Git tracked)                    â”‚
â”‚  âœ… Detailed values (raw features)                      â”‚
â”‚  âœ… Can change frequently (refactoring)                 â”‚
â”‚  âœ… Data Scientists access directly                     â”‚
â”‚  âœ… Training labels included                            â”‚
â”‚  âœ… No data leakage controls (in model)                 â”‚
â”‚                                                         â”‚
â”‚  Example: ftr_customer_behavior                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚  â”‚ customer_code   | payment_comp_rt â”‚ updated_at       â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                   â”‚
â”‚  â”‚ CUST001         | 0.95            â”‚ 2025-11-01      â”‚
â”‚  â”‚ CUST001         | 0.93            â”‚ 2025-10-01 (v2) â”‚
â”‚  â”‚ CUST002         | 0.87            â”‚ 2025-11-01      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚                                                         â”‚
â”‚  SLA: Hourly refresh, 99% availability                  â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              ANALYTICS SERVE LAYER (GOLD)               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                         â”‚
â”‚  Purpose: Business Intelligence & KPI Dashboards       â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                â”‚
â”‚                                                         â”‚
â”‚  âœ… Pre-calculated aggregates (daily/weekly)            â”‚
â”‚  âœ… Denormalized Star schema                            â”‚
â”‚  âœ… Model predictions + scores served                   â”‚
â”‚  âœ… Optimized for BI tools query speed                  â”‚
â”‚  âœ… Stable structure (rarely change)                    â”‚
â”‚  âœ… Row-level security policies                         â”‚
â”‚  âœ… No training labels                                  â”‚
â”‚  âœ… BI Analysts access (not researchers)                â”‚
â”‚                                                         â”‚
â”‚  Example: kpi_daily_revenue                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚  â”‚ date_key | total_revenue | growth â”‚                  â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                   â”‚
â”‚  â”‚ 20251101 | 5,234,567,890  | +12% â”‚                  â”‚
â”‚  â”‚ 20251031 | 4,664,820,123  | +8%  â”‚                  â”‚
â”‚  â”‚ 20251030 | 4,319,084,932  | -3%  â”‚                  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚                                                         â”‚
â”‚  SLA: < 5s query latency, 99.9% availability            â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

KEY DIFFERENCES
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Aspect           â”‚ Silver (Feature) â”‚ Gold (Analytics)  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Grain            â”‚ Row-level detail â”‚ Aggregated daily  â”‚
â”‚ Ownership        â”‚ Data Science     â”‚ BI/Analytics      â”‚
â”‚ Change Frequency â”‚ Often (iterative)â”‚ Rarely (stable)   â”‚
â”‚ Query Performanceâ”‚ N/A (batch)      â”‚ < 5s (online)     â”‚
â”‚ Data Loss        â”‚ No (raw)         â”‚ Lossy (aggregate) â”‚
â”‚ Access Pattern   â”‚ Full table read  â”‚ WHERE/GROUP BY    â”‚
â”‚ Size             â”‚ Large (all hist) â”‚ Medium (summary)  â”‚
â”‚ Tests            â”‚ Distribution     â”‚ SLA monitoring    â”‚
â”‚ Version Control  â”‚ Code + artifacts â”‚ Schema only       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **Diagram 4: ML Pipeline Orchestration (Airflow DAG)**

```
DAG: ml_training_daily (Runs 2 AM every day)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. data_quality_check              â”‚
â”‚  â”œâ”€ Great Expectations              â”‚
â”‚  â”‚  â€¢ Null rate < 5%                â”‚
â”‚  â”‚  â€¢ Freshness â‰¤ 2 days            â”‚
â”‚  â”‚  â€¢ Distribution shift (KL)       â”‚
â”‚  â””â”€ Fail â†’ Alert email, stop dag    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚ (success)
               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. feature_preparation                  â”‚
â”‚  â”œâ”€ Query Silver features (SQL)          â”‚
â”‚  â”‚  â€¢ ml_training_payment_pred           â”‚
â”‚  â”‚  â€¢ Filter: recent 30 days             â”‚
â”‚  â”œâ”€ Load to Pandas DataFrame             â”‚
â”‚  â””â”€ Save to /tmp/training_data.csv       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. model_training                       â”‚
â”‚  â”œâ”€ Load CSV                             â”‚
â”‚  â”œâ”€ MLflow: Start experiment run         â”‚
â”‚  â”‚  â€¢ Algo: Prophet + XGBoost            â”‚
â”‚  â”‚  â€¢ Split: 80/20 train/val             â”‚
â”‚  â”‚  â€¢ Cross-validation: 5-fold           â”‚
â”‚  â”œâ”€ Log metrics: MAPE, RMSE              â”‚
â”‚  â”œâ”€ Log artifacts: model.pkl             â”‚
â”‚  â”œâ”€ Log params: seasonality, trend       â”‚
â”‚  â””â”€ Best model â†’ Model Registry          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  4. model_evaluation                     â”‚
â”‚  â”œâ”€ Holdout test set evaluation          â”‚
â”‚  â”‚  â€¢ MAPE < 15% âœ… Continue             â”‚
â”‚  â”‚  â€¢ MAPE â‰¥ 15% âŒ Manual review        â”‚
â”‚  â”œâ”€ Logging: Test metrics                â”‚
â”‚  â””â”€ Fail â†’ SLA alert to ML team          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚ (passed)
               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  5. batch_inference                      â”‚
â”‚  â”œâ”€ Load champion model v1.2.3           â”‚
â”‚  â”œâ”€ Score all active invoices (Silver)   â”‚
â”‚  â”‚  â€¢ 50k+ invoices                      â”‚
â”‚  â”‚  â€¢ Parallel processing (10 workers)    â”‚
â”‚  â”œâ”€ Generate: predicted_date, confidence â”‚
â”‚  â””â”€ Write to temp table (Trino)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  6. dbt_load_scores                      â”‚
â”‚  â”œâ”€ dbt run --select gold.ml_scores      â”‚
â”‚  â”‚  â€¢ Load from temp â†’ gold.score_*      â”‚
â”‚  â”‚  â€¢ Partition by date_key              â”‚
â”‚  â”œâ”€ dbt test                             â”‚
â”‚  â”‚  â€¢ Not null checks                    â”‚
â”‚  â”‚  â€¢ Confidence âˆˆ [0,1]                 â”‚
â”‚  â”‚  â€¢ Record count > 0                   â”‚
â”‚  â””â”€ Success â†’ Mark task complete         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â†“
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ ğŸŸ¢ SUCCESS   â”‚
         â”‚ Scores live  â”‚
         â”‚ in Gold      â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         
         Slack: "âœ… Payment model v1.2.3 trained. MAPE=12.3%"
         Dashboard: Refresh predictions view
```

### **Diagram 5: Dependencies & DAG Build Order**

```
DEPENDENCY GRAPH (Layers & Order)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

TIER 1: Seeds & Bronze
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ seed_*                   â”‚ â† Reference data (no deps)
â”‚ bronze.sales_snapshot_*  â”‚ â† Raw data (external)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â†“

TIER 2: Silver Staging (Parallel)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ â”Œâ”€stg_orders_vn                                â”‚
â”‚ â”œâ”€stg_payments_vn           (all independent)   â”‚
â”‚ â”œâ”€stg_shipments_vn                            â”‚
â”‚ â”œâ”€stg_bank_txn_vn                             â”‚
â”‚ â””â”€stg_ar_invoices_vn        â­ NEW             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â†“

TIER 3: Silver Features (Parallel)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ â”Œâ”€ftr_customer_behavior â† stg_orders, stg_pmt  â”‚
â”‚ â”œâ”€ftr_invoice_risk â† stg_ar_invoices           â”‚
â”‚ â”œâ”€ftr_payment_pattern â† stg_payments_vn        â”‚
â”‚ â”œâ”€ftr_seasonality â† stg_orders_vn              â”‚
â”‚ â””â”€ftr_macroeconomic â† external data source     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â†“

TIER 4: Silver ML Training Datasets
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ml_training_payment_pred                       â”‚
â”‚  â”œâ”€ Depends: ftr_customer_behavior             â”‚
â”‚  â”œâ”€ Depends: ftr_invoice_risk                  â”‚
â”‚  â””â”€ Depends: ftr_payment_pattern               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â†“

TIER 5: Gold Dimensions (Parallel)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ â”Œâ”€ dim_date          (no deps)                  â”‚
â”‚ â”œâ”€ dim_customer â† stg_orders_vn                â”‚
â”‚ â”œâ”€ dim_product â† stg_orders_vn                 â”‚
â”‚ â”œâ”€ dim_channel â† seed_channel_map              â”‚
â”‚ â”œâ”€ dim_payment_method â† seed_payment_*         â”‚
â”‚ â”œâ”€ dim_carrier â† seed_carrier_map              â”‚
â”‚ â”œâ”€ dim_geo â† seed_provinces                    â”‚
â”‚ â””â”€ dim_ar_customer â† ftr_customer_behavior  â­ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â†“

TIER 6: Gold Facts (Parallel, deps on Dims)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ â”Œâ”€ fact_orders â† stg_orders_vn, dim_channel    â”‚
â”‚ â”œâ”€ fact_payments â† stg_payments, dim_*         â”‚
â”‚ â”œâ”€ fact_shipments â† stg_shipments, dim_carrier â”‚
â”‚ â”œâ”€ fact_bank_txn â† stg_bank_txn, dim_date      â”‚
â”‚ â””â”€ fact_ar_invoices â† ftr_invoice_risk, dims â­â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â†“

TIER 7: Gold Links (Parallel, deps on Facts)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ â”œâ”€ link_order_payment â† fact_orders, fact_pmt  â”‚
â”‚ â”œâ”€ link_payment_bank â† fact_payments, fact_txn â”‚
â”‚ â””â”€ link_order_shipment â† fact_orders, fact_shipâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â†“

TIER 8: Gold KPIs (Parallel, deps on Facts/Links)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ â”œâ”€ kpi_daily_revenue â† fact_orders, dim_date   â”‚
â”‚ â”œâ”€ kpi_payment_success â† link_order_payment    â”‚
â”‚ â”œâ”€ kpi_reconciliation â† link_order_payment     â”‚
â”‚ â””â”€ kpi_ar_dso â† fact_ar_invoices               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â†“

TIER 9: Gold ML Scores (External, serial)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ (Written by Airflow ML pipeline)               â”‚
â”‚ â”œâ”€ score_payment_pred (via MLflow inference)   â”‚
â”‚ â”œâ”€ score_ar_priority                          â”‚
â”‚ â”œâ”€ score_churn_risk                           â”‚
â”‚ â””â”€ score_cashflow_fcst                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

EXECUTION COMMANDS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# PARALLEL (All at once - dbt handles deps)
dbt build

# SEQUENTIAL (Explicit)
dbt run --select silver.staging
dbt run --select silver.features
dbt run --select silver.ml_training
dbt run --select gold.dims
dbt run --select gold.facts
dbt run --select gold.links
dbt run --select gold.kpi

# WITH SELECTOR (Recommended)
dbt build --selector build_warehouse
```

---

## ï¿½ğŸ“š REFERENCE ARCHITECTURE

**Best Practices**:
- **Netflix**: Feature Store (Metaflow) â†’ Distributed training â†’ Batch serving
- **Uber**: Michelangelo: Feature store (Cassandra) â†’ Distributed ML â†’ Real-time serving
- **Airbnb**: Feature store with Spark SQL + ML pipeline orchestration

**Key Principle**: 
> *"Train on raw data (Silver), serve aggregated predictions (Gold)"* 

This separates concerns, enables reproducibility, and allows data science and BI to work independently.

---

**Document Version**: 2.0 (ML-First Architecture + Directory Structure)  
**Last Updated**: 2025-11-01  
**Status**: Ready for Implementation  
**Review Cycle**: Monthly (check for feature drift, model performance)
